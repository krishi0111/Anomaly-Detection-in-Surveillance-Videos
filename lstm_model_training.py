# -*- coding: utf-8 -*-
"""LSTM model training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LjkP1up6Ph21vCfSUDsasr02pBE8JEa8
"""

# Upload your Kaggle API key (you need to do this once)
from google.colab import files
files.upload()  # Upload kaggle.json when prompted

# Create a Kaggle directory and move the API key
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d mateohervas/dcsass-dataset --unzip

"""# **RoadAccidents**"""

import os
import cv2
import pandas as pd
from tqdm import tqdm

# Define paths
video_root_dir = "/content/DCSASS Dataset/RoadAccidents"  # Root folder containing RoadAccidents video folders
label_file_path = "/content/DCSASS Dataset/Labels/RoadAccidents.csv"  # CSV file with labels
frame_output_dir = "/content/extracted_frames/RoadAccidents"

# Load labels
labels_df = pd.read_csv(label_file_path, header=None, names=["video_name", "category", "label"])
labels_dict = dict(zip(labels_df["video_name"], labels_df["label"]))

# Create directories for labeled frames
os.makedirs(os.path.join(frame_output_dir, "Anomaly"), exist_ok=True)
os.makedirs(os.path.join(frame_output_dir, "Normal"), exist_ok=True)

# Frame extraction settings
FRAME_RATE = 1  # Extract 1 frame per second

def extract_frames(video_path, video_name, label):
    """Extract frames and save them based on the anomaly label."""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Could not open video: {video_path}")
        return

    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_interval = max(1, fps // FRAME_RATE)

    output_label_dir = "Anomaly" if label == 1 else "Normal"
    save_path = os.path.join(frame_output_dir, output_label_dir)

    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if count % frame_interval == 0:
            frame_filename = os.path.join(save_path, f"{video_name}_frame_{count}.jpg")
            cv2.imwrite(frame_filename, frame)
        count += 1
    cap.release()

# Process all nested videos inside RoadAccidents folder
for folder in os.listdir(video_root_dir):
    folder_path = os.path.join(video_root_dir, folder)
    if os.path.isdir(folder_path):  # Ensure it's a folder
        for video in os.listdir(folder_path):
            if video.endswith(".mp4"):  # Process only video files
                video_path = os.path.join(folder_path, video)
                video_name = os.path.splitext(video)[0]  # Remove extension

                # Get label (default to Normal if not found)
                label = labels_dict.get(video_name, 0)
                extract_frames(video_path, video_name, label)

print(" Frame extraction complete! ")

labels_dict

import os
import pandas as pd
import shutil

# Define paths
normal_dir = "/content/extracted_frames/RoadAccidents/Anomaly"
abnormal_dir = "/content/extracted_frames/RoadAccidents/Normal"
combined_dir = "/content/Extracted_frames/RoadAccidents/All_Frames"  # New folder for all frames
csv_file = "/content/RoadAccidents_labels.csv"  # Output CSV file

# Create the combined folder if not exists
os.makedirs(combined_dir, exist_ok=True)

# Prepare list to store frame paths and labels
data = []

# Process Normal frames (Label = 0)
for filename in os.listdir(normal_dir):
    src_path = os.path.join(normal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 0])  # Label 0 for normal

# Process Abnormal frames (Label = 1)
for filename in os.listdir(abnormal_dir):
    src_path = os.path.join(abnormal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 1])  # Label 1 for abnormal

# Save data to CSV
df = pd.DataFrame(data, columns=["frame_path", "label"])
df.to_csv(csv_file, index=False)

print("Frames combined and labeled CSV created:", csv_file)

import os

frames_dir = "/content/Extracted_frames/RoadAccidents/All_Frames"  # Change this path if needed

total_frames = len(os.listdir(frames_dir))
print(f"Total number of frames: {total_frames}")

import shutil

frames_dir = "/content/Extracted_frames/RoadAccidents/All_Frames"  # Change this path if needed
zip_path = "/content/extracted_RoadAccidents_frames.zip"

shutil.make_archive(zip_path.replace(".zip", ""), 'zip', frames_dir)

from google.colab import files
files.download(zip_path)

import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image

frames_dir = "/content/Extracted_frames/RoadAccidents/All_Frames"  # Path where frames are stored
labels_file = "/content/RoadAccidents_labels.csv"  # CSV with labels for frames
feature_output_dir = "/content/extracted_features/RoadAccidents"  # Folder to save features
os.makedirs(feature_output_dir, exist_ok=True)

# Load CSV containing frame labels (0 = normal, 1 = anomaly)
labels_df = pd.read_csv(labels_file)
frame_labels = dict(zip(labels_df["frame_path"], labels_df["label"]))  # Map frame name to label

# Load ResNet50 without the top classification layer
base_model = ResNet50(weights="imagenet", include_top=False, pooling="avg")
model = Model(inputs=base_model.input, outputs=base_model.output)

def extract_features(frame_path):
    """Extract ResNet50 features from a frame."""
    img = image.load_img(frame_path, target_size=(224, 224))  # Resize to ResNet50 input
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Expand dims for batch size
    img_array = preprocess_input(img_array)  # Normalize for ResNet50

    features = model.predict(img_array)  # Extract features
    return features.flatten()  # Convert to 1D array

import os
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Model

# Define paths
frames_dir = "/content/Extracted_frames/RoadAccidents/All_Frames"  # Folder containing extracted frames
labels_file = "/content/RoadAccidents_labels.csv"  # CSV containing frame labels
feature_output_dir = "/content/extracted_features/RoadAccidents"  # Folder to save .npy features
os.makedirs(feature_output_dir, exist_ok=True)

# Load labels CSV and sort by frame name
labels_df = pd.read_csv(labels_file)
labels_df["frame_path"] = labels_df["frame_path"].apply(os.path.basename)  # Ensure only file names are used
labels_df = labels_df.sort_values(by="frame_path")  # Sort labels by frame name
frame_labels = dict(zip(labels_df["frame_path"], labels_df["label"]))

# Load ResNet50 model (without top layer for feature extraction)
base_model = ResNet50(weights="imagenet", include_top=False, pooling="avg")
model = Model(inputs=base_model.input, outputs=base_model.output)

# Sort frames to maintain order
frame_names = sorted(os.listdir(frames_dir))  # Ensure consistent order
features_list = []
metadata_list = []

def extract_features(frame_path):
    """Extract ResNet50 features from a single frame."""
    frame = cv2.imread(frame_path)
    if frame is None:
        print(f"Could not open frame: {frame_path}")
        return None

    frame = cv2.resize(frame, (224, 224))  # Resize for ResNet50
    frame = preprocess_input(frame)  # Apply preprocessing
    frame = np.expand_dims(frame, axis=0)  # Add batch dimension

    features = model.predict(frame)  # Extract features
    return features.flatten()  # Flatten features to 1D

# Process all frames in sorted order
for frame_name in tqdm(frame_names):
    frame_path = os.path.join(frames_dir, frame_name)

    if frame_labels.get(frame_name, None) is not None:  # Ensure frame has a label
        features = extract_features(frame_path)
        if features is not None:
            # Save extracted features as .npy
            feature_file = os.path.join(feature_output_dir, frame_name.replace(".jpg", ".npy"))
            np.save(feature_file, features)

            # Store file path and corresponding label
            features_list.append(feature_file)
            metadata_list.append([feature_file, frame_labels[frame_name]])

# Convert metadata to CSV
metadata_df = pd.DataFrame(metadata_list, columns=["feature_path", "label"])
metadata_df.to_csv(os.path.join(feature_output_dir, "labels.csv"), index=False)

print("Feature extraction complete! ")

import shutil

frames_dir = "/content/extracted_features/RoadAccidents"  # Change this path if needed
zip_path = "/content/extracted_RoadAccidents_features.zip"

shutil.make_archive(zip_path.replace(".zip", ""), 'zip', frames_dir)

from google.colab import files
files.download(zip_path)

"""# **Robbery**"""

import os
import cv2
import pandas as pd
from tqdm import tqdm

# Define paths
video_root_dir = "/content/DCSASS Dataset/Robbery"
label_file_path = "/content/DCSASS Dataset/Labels/Robbery.csv"  # CSV file with labels
frame_output_dir = "/content/extracted_frames/Robbery"

# Load labels
labels_df = pd.read_csv(label_file_path, header=None, names=["video_name", "category", "label"])
labels_dict = dict(zip(labels_df["video_name"], labels_df["label"]))

# Create directories for labeled frames
os.makedirs(os.path.join(frame_output_dir, "Anomaly"), exist_ok=True)
os.makedirs(os.path.join(frame_output_dir, "Normal"), exist_ok=True)

# Frame extraction settings
FRAME_RATE = 1  # Extract 1 frame per second

def extract_frames(video_path, video_name, label):
    """Extract frames and save them based on the anomaly label."""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Could not open video: {video_path}")
        return

    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_interval = max(1, fps // FRAME_RATE)

    output_label_dir = "Anomaly" if label == 1 else "Normal"
    save_path = os.path.join(frame_output_dir, output_label_dir)

    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if count % frame_interval == 0:
            frame_filename = os.path.join(save_path, f"{video_name}_frame_{count}.jpg")
            cv2.imwrite(frame_filename, frame)
        count += 1
    cap.release()

for folder in os.listdir(video_root_dir):
    folder_path = os.path.join(video_root_dir, folder)
    if os.path.isdir(folder_path):  # Ensure it's a folder
        for video in os.listdir(folder_path):
            if video.endswith(".mp4"):  # Process only video files
                video_path = os.path.join(folder_path, video)
                video_name = os.path.splitext(video)[0]  # Remove extension

                # Get label (default to Normal if not found)
                label = labels_dict.get(video_name, 0)
                extract_frames(video_path, video_name, label)

print(" Frame extraction complete! ")

import os
import pandas as pd
import shutil

# Define paths
normal_dir = "/content/extracted_frames/Robbery/Anomaly"
abnormal_dir = "/content/extracted_frames/Robbery/Normal"
combined_dir = "/content/Extracted_frames/Robbery/All_Frames"  # New folder for all frames
csv_file = "/content/Robbery_labels.csv"  # Output CSV file

# Create the combined folder if not exists
os.makedirs(combined_dir, exist_ok=True)

# Prepare list to store frame paths and labels
data = []

# Process Normal frames (Label = 0)
for filename in os.listdir(normal_dir):
    src_path = os.path.join(normal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 0])  # Label 0 for normal

# Process Abnormal frames (Label = 1)
for filename in os.listdir(abnormal_dir):
    src_path = os.path.join(abnormal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 1])  # Label 1 for abnormal

# Save data to CSV
df = pd.DataFrame(data, columns=["frame_path", "label"])
df.to_csv(csv_file, index=False)

print("Frames combined and labeled CSV created:", csv_file)

import os
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Model

# Define paths
frames_dir = "/content/Extracted_frames/Robbery/All_Frames"  # Folder containing extracted frames
labels_file = "/content/Robbery_labels.csv"  # CSV containing frame labels
feature_output_dir = "/content/extracted_features/Robbery"  # Folder to save .npy features
os.makedirs(feature_output_dir, exist_ok=True)

# Load labels CSV and sort by frame name
labels_df = pd.read_csv(labels_file)
labels_df["frame_path"] = labels_df["frame_path"].apply(os.path.basename)  # Ensure only file names are used
labels_df = labels_df.sort_values(by="frame_path")  # Sort labels by frame name
frame_labels = dict(zip(labels_df["frame_path"], labels_df["label"]))

# Load ResNet50 model (without top layer for feature extraction)
base_model = ResNet50(weights="imagenet", include_top=False, pooling="avg")
model = Model(inputs=base_model.input, outputs=base_model.output)

# Sort frames to maintain order
frame_names = sorted(os.listdir(frames_dir))  # Ensure consistent order
features_list = []
metadata_list = []

def extract_features(frame_path):
    """Extract ResNet50 features from a single frame."""
    frame = cv2.imread(frame_path)
    if frame is None:
        print(f"Could not open frame: {frame_path}")
        return None

    frame = cv2.resize(frame, (224, 224))  # Resize for ResNet50
    frame = preprocess_input(frame)  # Apply preprocessing
    frame = np.expand_dims(frame, axis=0)  # Add batch dimension

    features = model.predict(frame)  # Extract features
    return features.flatten()  # Flatten features to 1D

# Process all frames in sorted order
for frame_name in tqdm(frame_names):
    frame_path = os.path.join(frames_dir, frame_name)

    if frame_labels.get(frame_name, None) is not None:  # Ensure frame has a label
        features = extract_features(frame_path)
        if features is not None:
            # Save extracted features as .npy
            feature_file = os.path.join(feature_output_dir, frame_name.replace(".jpg", ".npy"))
            np.save(feature_file, features)

            # Store file path and corresponding label
            features_list.append(feature_file)
            metadata_list.append([feature_file, frame_labels[frame_name]])

# Convert metadata to CSV
metadata_df = pd.DataFrame(metadata_list, columns=["feature_path", "label"])
metadata_df.to_csv(os.path.join(feature_output_dir, "labels.csv"), index=False)

print("Feature extraction complete! ")

import shutil

frames_dir = "/content/extracted_features/Robbery"  # Change this path if needed
zip_path = "/content/extracted_Robbery_features.zip"

shutil.make_archive(zip_path.replace(".zip", ""), 'zip', frames_dir)

from google.colab import files
files.download(zip_path)

"""# **Shooting**"""

import os
import cv2
import pandas as pd
from tqdm import tqdm

# Define paths
video_root_dir = "/content/DCSASS Dataset/Shooting"
label_file_path = "/content/DCSASS Dataset/Labels/Shooting.csv"  # CSV file with labels
frame_output_dir = "/content/extracted_frames/Shooting"

# Load labels
labels_df = pd.read_csv(label_file_path, header=None, names=["video_name", "category", "label"])
labels_dict = dict(zip(labels_df["video_name"], labels_df["label"]))

# Create directories for labeled frames
os.makedirs(os.path.join(frame_output_dir, "Anomaly"), exist_ok=True)
os.makedirs(os.path.join(frame_output_dir, "Normal"), exist_ok=True)

# Frame extraction settings
FRAME_RATE = 1  # Extract 1 frame per second

def extract_frames(video_path, video_name, label):
    """Extract frames and save them based on the anomaly label."""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Could not open video: {video_path}")
        return

    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_interval = max(1, fps // FRAME_RATE)

    output_label_dir = "Anomaly" if label == 1 else "Normal"
    save_path = os.path.join(frame_output_dir, output_label_dir)

    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if count % frame_interval == 0:
            frame_filename = os.path.join(save_path, f"{video_name}_frame_{count}.jpg")
            cv2.imwrite(frame_filename, frame)
        count += 1
    cap.release()

for folder in os.listdir(video_root_dir):
    folder_path = os.path.join(video_root_dir, folder)
    if os.path.isdir(folder_path):  # Ensure it's a folder
        for video in os.listdir(folder_path):
            if video.endswith(".mp4"):  # Process only video files
                video_path = os.path.join(folder_path, video)
                video_name = os.path.splitext(video)[0]  # Remove extension

                # Get label (default to Normal if not found)
                label = labels_dict.get(video_name, 0)
                extract_frames(video_path, video_name, label)

print(" Frame extraction complete! ")

import os
import pandas as pd
import shutil

# Define paths
normal_dir = "/content/extracted_frames/Shooting/Anomaly"
abnormal_dir = "/content/extracted_frames/Shooting/Normal"
combined_dir = "/content/Extracted_frames/Shooting/All_Frames"  # New folder for all frames
csv_file = "/content/Shooting_labels.csv"  # Output CSV file

# Create the combined folder if not exists
os.makedirs(combined_dir, exist_ok=True)

# Prepare list to store frame paths and labels
data = []

# Process Normal frames (Label = 0)
for filename in os.listdir(normal_dir):
    src_path = os.path.join(normal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 0])  # Label 0 for normal

# Process Abnormal frames (Label = 1)
for filename in os.listdir(abnormal_dir):
    src_path = os.path.join(abnormal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 1])  # Label 1 for abnormal

# Save data to CSV
df = pd.DataFrame(data, columns=["frame_path", "label"])
df.to_csv(csv_file, index=False)

print("Frames combined and labeled CSV created:", csv_file)

import os
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Model

# Define paths
frames_dir = "/content/Extracted_frames/Shooting/All_Frames"  # Corrected path: 'Shooting' instead of 'Shootingy'
labels_file = "/content/Shooting_labels.csv"  # CSV containing frame labels
feature_output_dir = "/content/extracted_features/Shooting"  # Folder to save .npy features
os.makedirs(feature_output_dir, exist_ok=True)

# Load labels CSV and sort by frame name
labels_df = pd.read_csv(labels_file)
labels_df["frame_path"] = labels_df["frame_path"].apply(os.path.basename)  # Ensure only file names are used
labels_df = labels_df.sort_values(by="frame_path")  # Sort labels by frame name
frame_labels = dict(zip(labels_df["frame_path"], labels_df["label"]))

# Load ResNet50 model (without top layer for feature extraction)
base_model = ResNet50(weights="imagenet", include_top=False, pooling="avg")
model = Model(inputs=base_model.input, outputs=base_model.output)

# Sort frames to maintain order
frame_names = sorted(os.listdir(frames_dir))  # Ensure consistent order
features_list = []
metadata_list = []

def extract_features(frame_path):
    """Extract ResNet50 features from a single frame."""
    frame = cv2.imread(frame_path)
    if frame is None:
        print(f"Could not open frame: {frame_path}")
        return None

    frame = cv2.resize(frame, (224, 224))  # Resize for ResNet50
    frame = preprocess_input(frame)  # Apply preprocessing
    frame = np.expand_dims(frame, axis=0)  # Add batch dimension

    features = model.predict(frame)  # Extract features
    return features.flatten()  # Flatten features to 1D

# Process all frames in sorted order
for frame_name in tqdm(frame_names):
    frame_path = os.path.join(frames_dir, frame_name)

    if frame_labels.get(frame_name, None) is not None:  # Ensure frame has a label
        features = extract_features(frame_path)
        if features is not None:
            # Save extracted features as .npy
            feature_file = os.path.join(feature_output_dir, frame_name.replace(".jpg", ".npy"))
            np.save(feature_file, features)

            # Store file path and corresponding label
            features_list.append(feature_file)
            metadata_list.append([feature_file, frame_labels[frame_name]])

# Convert metadata to CSV
metadata_df = pd.DataFrame(metadata_list, columns=["feature_path", "label"])
metadata_df.to_csv(os.path.join(feature_output_dir, "labels.csv"), index=False)

print("Feature extraction complete! ")

import shutil

frames_dir = "/content/extracted_features/Shooting"  # Change this path if needed
zip_path = "/content/extracted_Shooting_features.zip"

shutil.make_archive(zip_path.replace(".zip", ""), 'zip', frames_dir)

from google.colab import files
files.download(zip_path)

"""# **Shoplifting**"""

import os
import cv2
import pandas as pd
from tqdm import tqdm

# Define paths
video_root_dir = "/content/DCSASS Dataset/Shoplifting"
label_file_path = "/content/DCSASS Dataset/Labels/Shoplifting.csv"  # CSV file with labels
frame_output_dir = "/content/extracted_frames/Shoplifting"

# Load labels
labels_df = pd.read_csv(label_file_path, header=None, names=["video_name", "category", "label"])
labels_dict = dict(zip(labels_df["video_name"], labels_df["label"]))

# Create directories for labeled frames
os.makedirs(os.path.join(frame_output_dir, "Anomaly"), exist_ok=True)
os.makedirs(os.path.join(frame_output_dir, "Normal"), exist_ok=True)

# Frame extraction settings
FRAME_RATE = 1  # Extract 1 frame per second

def extract_frames(video_path, video_name, label):
    """Extract frames and save them based on the anomaly label."""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Could not open video: {video_path}")
        return

    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_interval = max(1, fps // FRAME_RATE)

    output_label_dir = "Anomaly" if label == 1 else "Normal"
    save_path = os.path.join(frame_output_dir, output_label_dir)

    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if count % frame_interval == 0:
            frame_filename = os.path.join(save_path, f"{video_name}_frame_{count}.jpg")
            cv2.imwrite(frame_filename, frame)
        count += 1
    cap.release()

for folder in os.listdir(video_root_dir):
    folder_path = os.path.join(video_root_dir, folder)
    if os.path.isdir(folder_path):  # Ensure it's a folder
        for video in os.listdir(folder_path):
            if video.endswith(".mp4"):  # Process only video files
                video_path = os.path.join(folder_path, video)
                video_name = os.path.splitext(video)[0]  # Remove extension

                # Get label (default to Normal if not found)
                label = labels_dict.get(video_name, 0)
                extract_frames(video_path, video_name, label)

print(" Frame extraction complete! ")

import os
import pandas as pd
import shutil

# Define paths
normal_dir = "/content/extracted_frames/Shoplifting/Anomaly"
abnormal_dir = "/content/extracted_frames/Shoplifting/Normal"
combined_dir = "/content/Extracted_frames/Shoplifting/All_Frames"  # New folder for all frames
csv_file = "/content/Shoplifting_labels.csv"  # Output CSV file

# Create the combined folder if not exists
os.makedirs(combined_dir, exist_ok=True)

# Prepare list to store frame paths and labels
data = []

# Process Normal frames (Label = 0)
for filename in os.listdir(normal_dir):
    src_path = os.path.join(normal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 0])  # Label 0 for normal

# Process Abnormal frames (Label = 1)
for filename in os.listdir(abnormal_dir):
    src_path = os.path.join(abnormal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 1])  # Label 1 for abnormal

# Save data to CSV
df = pd.DataFrame(data, columns=["frame_path", "label"])
df.to_csv(csv_file, index=False)

print("Frames combined and labeled CSV created:", csv_file)

import os
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Model

# Define paths
frames_dir = "/content/Extracted_frames/Shoplifting/All_Frames"  # Corrected path: 'Shooting' instead of 'Shootingy'
labels_file = "/content/Shoplifting_labels.csv"  # CSV containing frame labels
feature_output_dir = "/content/extracted_features/Shoplifting"  # Folder to save .npy features
os.makedirs(feature_output_dir, exist_ok=True)

# Load labels CSV and sort by frame name
labels_df = pd.read_csv(labels_file)
labels_df["frame_path"] = labels_df["frame_path"].apply(os.path.basename)  # Ensure only file names are used
labels_df = labels_df.sort_values(by="frame_path")  # Sort labels by frame name
frame_labels = dict(zip(labels_df["frame_path"], labels_df["label"]))

# Load ResNet50 model (without top layer for feature extraction)
base_model = ResNet50(weights="imagenet", include_top=False, pooling="avg")
model = Model(inputs=base_model.input, outputs=base_model.output)

# Sort frames to maintain order
frame_names = sorted(os.listdir(frames_dir))  # Ensure consistent order
features_list = []
metadata_list = []

def extract_features(frame_path):
    """Extract ResNet50 features from a single frame."""
    frame = cv2.imread(frame_path)
    if frame is None:
        print(f"Could not open frame: {frame_path}")
        return None

    frame = cv2.resize(frame, (224, 224))  # Resize for ResNet50
    frame = preprocess_input(frame)  # Apply preprocessing
    frame = np.expand_dims(frame, axis=0)  # Add batch dimension

    features = model.predict(frame)  # Extract features
    return features.flatten()  # Flatten features to 1D

# Process all frames in sorted order
for frame_name in tqdm(frame_names):
    frame_path = os.path.join(frames_dir, frame_name)

    if frame_labels.get(frame_name, None) is not None:  # Ensure frame has a label
        features = extract_features(frame_path)
        if features is not None:
            # Save extracted features as .npy
            feature_file = os.path.join(feature_output_dir, frame_name.replace(".jpg", ".npy"))
            np.save(feature_file, features)

            # Store file path and corresponding label
            features_list.append(feature_file)
            metadata_list.append([feature_file, frame_labels[frame_name]])

# Convert metadata to CSV
metadata_df = pd.DataFrame(metadata_list, columns=["feature_path", "label"])
metadata_df.to_csv(os.path.join(feature_output_dir, "labels.csv"), index=False)

print("Feature extraction complete! ")

import shutil

frames_dir = "/content/extracted_features/Shoplifting"  # Change this path if needed
zip_path = "/content/extracted_Shoplifting_features.zip"

shutil.make_archive(zip_path.replace(".zip", ""), 'zip', frames_dir)

from google.colab import files
files.download(zip_path)

"""# **Stealing**"""

import os
import cv2
import pandas as pd
from tqdm import tqdm

# Define paths
video_root_dir = "/content/DCSASS Dataset/Stealing"
label_file_path = "/content/DCSASS Dataset/Labels/Stealing.csv"  # CSV file with labels
frame_output_dir = "/content/extracted_frames/Stealing"

# Load labels
labels_df = pd.read_csv(label_file_path, header=None, names=["video_name", "category", "label"])
labels_dict = dict(zip(labels_df["video_name"], labels_df["label"]))

# Create directories for labeled frames
os.makedirs(os.path.join(frame_output_dir, "Anomaly"), exist_ok=True)
os.makedirs(os.path.join(frame_output_dir, "Normal"), exist_ok=True)

# Frame extraction settings
FRAME_RATE = 1  # Extract 1 frame per second

def extract_frames(video_path, video_name, label):
    """Extract frames and save them based on the anomaly label."""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Could not open video: {video_path}")
        return

    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_interval = max(1, fps // FRAME_RATE)

    output_label_dir = "Anomaly" if label == 1 else "Normal"
    save_path = os.path.join(frame_output_dir, output_label_dir)

    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if count % frame_interval == 0:
            frame_filename = os.path.join(save_path, f"{video_name}_frame_{count}.jpg")
            cv2.imwrite(frame_filename, frame)
        count += 1
    cap.release()

for folder in os.listdir(video_root_dir):
    folder_path = os.path.join(video_root_dir, folder)
    if os.path.isdir(folder_path):  # Ensure it's a folder
        for video in os.listdir(folder_path):
            if video.endswith(".mp4"):  # Process only video files
                video_path = os.path.join(folder_path, video)
                video_name = os.path.splitext(video)[0]  # Remove extension

                # Get label (default to Normal if not found)
                label = labels_dict.get(video_name, 0)
                extract_frames(video_path, video_name, label)

print(" Frame extraction complete! ")

import os
import pandas as pd
import shutil

# Define paths
normal_dir = "/content/extracted_frames/Stealing/Anomaly"
abnormal_dir = "/content/extracted_frames/Stealing/Normal"
combined_dir = "/content/Extracted_frames/Stealing/All_Frames"  # New folder for all frames
csv_file = "/content/Stealing_labels.csv"  # Output CSV file

# Create the combined folder if not exists
os.makedirs(combined_dir, exist_ok=True)

# Prepare list to store frame paths and labels
data = []

# Process Normal frames (Label = 0)
for filename in os.listdir(normal_dir):
    src_path = os.path.join(normal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 0])  # Label 0 for normal

# Process Abnormal frames (Label = 1)
for filename in os.listdir(abnormal_dir):
    src_path = os.path.join(abnormal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 1])  # Label 1 for abnormal

# Save data to CSV
df = pd.DataFrame(data, columns=["frame_path", "label"])
df.to_csv(csv_file, index=False)

print("Frames combined and labeled CSV created:", csv_file)

import os
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Model

# Define paths
frames_dir = "/content/Extracted_frames/Stealing/All_Frames"  # Corrected path: 'Shooting' instead of 'Shootingy'
labels_file = "/content/Stealing_labels.csv"  # CSV containing frame labels
feature_output_dir = "/content/extracted_features/Stealing"  # Folder to save .npy features
os.makedirs(feature_output_dir, exist_ok=True)

# Load labels CSV and sort by frame name
labels_df = pd.read_csv(labels_file)
labels_df["frame_path"] = labels_df["frame_path"].apply(os.path.basename)  # Ensure only file names are used
labels_df = labels_df.sort_values(by="frame_path")  # Sort labels by frame name
frame_labels = dict(zip(labels_df["frame_path"], labels_df["label"]))

# Load ResNet50 model (without top layer for feature extraction)
base_model = ResNet50(weights="imagenet", include_top=False, pooling="avg")
model = Model(inputs=base_model.input, outputs=base_model.output)

# Sort frames to maintain order
frame_names = sorted(os.listdir(frames_dir))  # Ensure consistent order
features_list = []
metadata_list = []

def extract_features(frame_path):
    """Extract ResNet50 features from a single frame."""
    frame = cv2.imread(frame_path)
    if frame is None:
        print(f"Could not open frame: {frame_path}")
        return None

    frame = cv2.resize(frame, (224, 224))  # Resize for ResNet50
    frame = preprocess_input(frame)  # Apply preprocessing
    frame = np.expand_dims(frame, axis=0)  # Add batch dimension

    features = model.predict(frame)  # Extract features
    return features.flatten()  # Flatten features to 1D

# Process all frames in sorted order
for frame_name in tqdm(frame_names):
    frame_path = os.path.join(frames_dir, frame_name)

    if frame_labels.get(frame_name, None) is not None:  # Ensure frame has a label
        features = extract_features(frame_path)
        if features is not None:
            # Save extracted features as .npy
            feature_file = os.path.join(feature_output_dir, frame_name.replace(".jpg", ".npy"))
            np.save(feature_file, features)

            # Store file path and corresponding label
            features_list.append(feature_file)
            metadata_list.append([feature_file, frame_labels[frame_name]])

# Convert metadata to CSV
metadata_df = pd.DataFrame(metadata_list, columns=["feature_path", "label"])
metadata_df.to_csv(os.path.join(feature_output_dir, "labels.csv"), index=False)

print("Feature extraction complete! ")

import shutil

frames_dir = "/content/extracted_features/Stealing"  # Change this path if needed
zip_path = "/content/extracted_Stealing_features.zip"

shutil.make_archive(zip_path.replace(".zip", ""), 'zip', frames_dir)

from google.colab import files
files.download(zip_path)

"""# **Vandalism**"""

import os
import cv2
import pandas as pd
from tqdm import tqdm

# Define paths
video_root_dir = "/content/DCSASS Dataset/Vandalism"
label_file_path = "/content/DCSASS Dataset/Labels/Vandalism.csv"  # CSV file with labels
frame_output_dir = "/content/extracted_frames/Vandalism"

# Load labels
labels_df = pd.read_csv(label_file_path, header=None, names=["video_name", "category", "label"])
labels_dict = dict(zip(labels_df["video_name"], labels_df["label"]))

# Create directories for labeled frames
os.makedirs(os.path.join(frame_output_dir, "Anomaly"), exist_ok=True)
os.makedirs(os.path.join(frame_output_dir, "Normal"), exist_ok=True)

# Frame extraction settings
FRAME_RATE = 1  # Extract 1 frame per second

def extract_frames(video_path, video_name, label):
    """Extract frames and save them based on the anomaly label."""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Could not open video: {video_path}")
        return

    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_interval = max(1, fps // FRAME_RATE)

    output_label_dir = "Anomaly" if label == 1 else "Normal"
    save_path = os.path.join(frame_output_dir, output_label_dir)

    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if count % frame_interval == 0:
            frame_filename = os.path.join(save_path, f"{video_name}_frame_{count}.jpg")
            cv2.imwrite(frame_filename, frame)
        count += 1
    cap.release()

for folder in os.listdir(video_root_dir):
    folder_path = os.path.join(video_root_dir, folder)
    if os.path.isdir(folder_path):  # Ensure it's a folder
        for video in os.listdir(folder_path):
            if video.endswith(".mp4"):  # Process only video files
                video_path = os.path.join(folder_path, video)
                video_name = os.path.splitext(video)[0]  # Remove extension

                # Get label (default to Normal if not found)
                label = labels_dict.get(video_name, 0)
                extract_frames(video_path, video_name, label)

print(" Frame extraction complete! ")

import os
import pandas as pd
import shutil

# Define paths
normal_dir = "/content/extracted_frames/Vandalism/Anomaly"
abnormal_dir = "/content/extracted_frames/Vandalism/Normal"
combined_dir = "/content/Extracted_frames/Vandalism/All_Frames"  # New folder for all frames
csv_file = "/content/Vandalism_labels.csv"  # Output CSV file

# Create the combined folder if not exists
os.makedirs(combined_dir, exist_ok=True)

# Prepare list to store frame paths and labels
data = []

# Process Normal frames (Label = 0)
for filename in os.listdir(normal_dir):
    src_path = os.path.join(normal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 0])  # Label 0 for normal

# Process Abnormal frames (Label = 1)
for filename in os.listdir(abnormal_dir):
    src_path = os.path.join(abnormal_dir, filename)
    dest_path = os.path.join(combined_dir, filename)

    shutil.copy(src_path, dest_path)  # Move frame to combined folder
    data.append([dest_path, 1])  # Label 1 for abnormal

# Save data to CSV
df = pd.DataFrame(data, columns=["frame_path", "label"])
df.to_csv(csv_file, index=False)

print("Frames combined and labeled CSV created:", csv_file)

import os
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Model

# Define paths
frames_dir = "/content/Extracted_frames/Vandalism/All_Frames"  # Corrected path: 'Shooting' instead of 'Shootingy'
labels_file = "/content/Vandalism_labels.csv"  # CSV containing frame labels
feature_output_dir = "/content/extracted_features/Vandalism"  # Folder to save .npy features
os.makedirs(feature_output_dir, exist_ok=True)

# Load labels CSV and sort by frame name
labels_df = pd.read_csv(labels_file)
labels_df["frame_path"] = labels_df["frame_path"].apply(os.path.basename)  # Ensure only file names are used
labels_df = labels_df.sort_values(by="frame_path")  # Sort labels by frame name
frame_labels = dict(zip(labels_df["frame_path"], labels_df["label"]))

# Load ResNet50 model (without top layer for feature extraction)
base_model = ResNet50(weights="imagenet", include_top=False, pooling="avg")
model = Model(inputs=base_model.input, outputs=base_model.output)

# Sort frames to maintain order
frame_names = sorted(os.listdir(frames_dir))  # Ensure consistent order
features_list = []
metadata_list = []

def extract_features(frame_path):
    """Extract ResNet50 features from a single frame."""
    frame = cv2.imread(frame_path)
    if frame is None:
        print(f"Could not open frame: {frame_path}")
        return None

    frame = cv2.resize(frame, (224, 224))  # Resize for ResNet50
    frame = preprocess_input(frame)  # Apply preprocessing
    frame = np.expand_dims(frame, axis=0)  # Add batch dimension

    features = model.predict(frame)  # Extract features
    return features.flatten()  # Flatten features to 1D

# Process all frames in sorted order
for frame_name in tqdm(frame_names):
    frame_path = os.path.join(frames_dir, frame_name)

    if frame_labels.get(frame_name, None) is not None:  # Ensure frame has a label
        features = extract_features(frame_path)
        if features is not None:
            # Save extracted features as .npy
            feature_file = os.path.join(feature_output_dir, frame_name.replace(".jpg", ".npy"))
            np.save(feature_file, features)

            # Store file path and corresponding label
            features_list.append(feature_file)
            metadata_list.append([feature_file, frame_labels[frame_name]])

# Convert metadata to CSV
metadata_df = pd.DataFrame(metadata_list, columns=["feature_path", "label"])
metadata_df.to_csv(os.path.join(feature_output_dir, "labels.csv"), index=False)

print("Feature extraction complete! ")

import shutil

frames_dir = "/content/extracted_features/Vandalism"  # Change this path if needed
zip_path = "/content/extracted_Vandalism_features.zip"

shutil.make_archive(zip_path.replace(".zip", ""), 'zip', frames_dir)

from google.colab import files
files.download(zip_path)

from google.colab import files
uploaded = files.upload()  # Manually select and upload the ZIP file

import pandas as pd

# Load label file
label_df = pd.read_csv("labels.csv")  # Replace with your actual file path

# Sort by the identifier column (replace "id" with your actual column name)
label_df = label_df.sort_values(by="id").reset_index(drop=True)

# Save the sorted label file
label_df.to_csv("sorted_labels.csv", index=False)

print("Label file sorted successfully!")

import zipfile
import os

zip_path = "/content/my_folder.zip"  # Replace with your ZIP file path
extract_path = "/content/extracted_folder"  # Destination folder

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Unzipping done! Files extracted to:", extract_path)

"""# **Labeling csv files**"""

from google.colab import files
uploaded = files.upload()  # Manually select and upload the ZIP file

import zipfile
import os

# Path to your uploaded zip file
zip_path = "/content/final_labels_csv.zip"  # Change this to your actual file path
extract_path = "/content/extracted_features_csv"  # Change this to where you want to extract

# Create the directory if it doesn't exist
os.makedirs(extract_path, exist_ok=True)

# Unzip the folder
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Extraction complete! 🎉 All files are now in:", extract_path)

import os

base_path = "/content/extracted_features_csv"

if os.path.exists(base_path):
    print("✅ Base folder found! Listing contents...")
    print(os.listdir(base_path))
else:
    print(f"❌ The folder '{base_path}' does not exist!")

import os

csv_folder = "/content/extracted_features_csv/final_labels.csv"  # Adjust path if needed
files_inside = os.listdir(csv_folder)

print("📂 Contents inside final_labels.csv folder:", files_inside)

import os
import pandas as pd

# Folder where all your label CSVs are stored
csv_folder = "/content/extracted_features_csv/final_labels.csv"  # Change if needed

# List of all categories in the correct order
categories = ["Abuse", "Arrest", "Arson", "Assault", "Burglary",
              "Explosion", "Fighting", "RoadAccidents", "Robbery", "Shooting",
              "Shoplifting", "Stealing", "Vandalism"]

final_labels = []

# Loop through each category file
for idx, category in enumerate(categories):
    file_name = f"extracted_{category}_features_labels.csv"
    file_path = os.path.join(csv_folder, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path)

        # Add a new column assigning the correct category index (1-13)
        df["final_label"] = idx + 1  # Since Normal is 0, anomalies start from 1

        final_labels.append(df)
    else:
        print(f"⚠️ File not found: {file_path}")

# Combine all data into a single DataFrame
final_df = pd.concat(final_labels, ignore_index=True)

# Save the merged labels
final_csv_path = "/content/extracted_features_csv/merged_labels.csv"
final_df.to_csv(final_csv_path, index=False)

print(f"✅ Final merged label file created at: {final_csv_path}")

# import os
# import pandas as pd

# # Folder where all your label CSVs are stored
# csv_folder = "/content/extracted_features_csv"

# # List of all anomaly categories
# categories = ["Abuse", "Arrest", "Arson", "Assault", "Burglary",
#               "Explosion", "Fighting", "RoadAccidents", "Robbery", "Shooting",
#               "Shoplifting", "Stealing", "Vandalism"]

# final_labels = []

# # Loop through each category file
# for idx, category in enumerate(categories):
#     file_name = f"extracted_{category}_features_labels.csv"
#     file_path = os.path.join(csv_folder, file_name)

#     if os.path.exists(file_path):
#         df = pd.read_csv(file_path)

#         # Add the correct category label (1-13)
#         df["final_label"] = idx + 1  # Since Normal is 0, anomalies start from 1

#         final_labels.append(df)
#     else:
#         print(f"⚠️ File not found: {file_path}")

# # Combine all anomalies into a single DataFrame
# anomalies_df = pd.concat(final_labels, ignore_index=True)

# # Creating Normal data from existing features (assuming normal frames exist in every CSV)
# normal_df = anomalies_df.copy()

# # Assign Normal label (0) to rows where the original label was 1 in the dataset
# # normal_df["final_label"] = 0

# # Merge Normal + Anomalies
# final_df = pd.concat([anomalies_df, normal_df], ignore_index=True)

# # Save the final dataset
# final_csv_path = "/content/extracted_features_csv/merged_labels_with_normal.csv"
# final_df.to_csv(final_csv_path, index=False)

# print(f"✅ Final merged label file with Normal (0) created at: {final_csv_path}")



import os
import pandas as pd

# Folder where all your label CSVs are stored
csv_folder = "/content/extracted_features_csv"

# List of all anomaly categories
categories = ["Abuse", "Arrest", "Arson", "Assault", "Burglary",
              "Explosion", "Fighting", "RoadAccidents", "Robbery", "Shooting",
              "Shoplifting", "Stealing", "Vandalism"]

final_labels = []

# Loop through each category file
for idx, category in enumerate(categories):
    file_name = f"extracted_{category}_features_labels.csv"
    file_path = os.path.join(csv_folder, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path)

        # Add the correct category label (1-13)
        df["final_label"] = idx + 1  # Normal = 0, so anomalies start at 1

        final_labels.append(df)
    else:
        print(f"⚠️ File not found: {file_path}")

# Concatenate all the DataFrames into one
combined_df = pd.concat(final_labels, ignore_index=True)

# Save to a final CSV
output_path = "/content/combined_anomaly_features.csv"
combined_df.to_csv(output_path, index=False)

print(f"✅ Combined CSV saved to {output_path}")
print(f"🔢 Total samples: {combined_df.shape[0]}, Columns: {combined_df.shape[1]}")

import pandas as pd

# Load your combined CSV file
csv_path = "/content/combined_anomaly_features.csv"
df = pd.read_csv(csv_path)

# Update: if the 2nd column (label) is 0, set the 3rd column (final_label) to 0
df.loc[df.iloc[:, 1] == 0, df.columns[2]] = 0

# Save the updated CSV
updated_path = "/content/combined_anomaly_features_updated.csv"
df.to_csv(updated_path, index=False)

print(f"✅ Updated CSV saved to: {updated_path}")

from sklearn.model_selection import train_test_split

# Load the dataset
dataset_path = "/content/extracted_features_csv/merged_labels_with_normal.csv"
df = pd.read_csv(dataset_path)

# Extract features (X) and labels (y)
X = df.drop(columns=["final_label"])  # Drop the label column
y = df["final_label"]  # Labels (0 = Normal, 1-13 = Anomalies)

# Train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"✅ Training data shape: {X_train.shape}")
print(f"✅ Testing data shape: {X_test.shape}")

"""# **Fianl Training**"""

import os
print(os.listdir("/content"))